# nginx.conf  --  docker-openresty
#
# This file is installed to:
#   `/usr/local/openresty/nginx/conf/nginx.conf`
# and is the file loaded by nginx at startup,
# unless the user specifies otherwise.
#
# It tracks the upstream OpenResty's `nginx.conf`, but removes the `server`
# section and adds this directive:
#     `include /etc/nginx/conf.d/*.conf;`
#
# The `docker-openresty` file `nginx.vh.default.conf` is copied to
# `/etc/nginx/conf.d/default.conf`.  It contains the `server section
# of the upstream `nginx.conf`.
#
# See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files
#

#user  nobody;
#worker_processes 1;

# Enables the use of JIT for regular expressions to speed-up their processing.
pcre_jit on;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

# 开启debug级别日志，否则ngx.log不能输出debug级别日志
# https://stackoverflow.com/questions/55975325/nothing-is-written-to-nginx-access-log-error-log-how-to-troubleshoot
error_log  logs/error.log  debug;

#pid        logs/nginx.pid;

events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    # Enables or disables the use of underscores in client request header fields.
    # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive.
    # underscores_in_headers off;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

        # Log in JSON Format
        # log_format nginxlog_json escape=json '{ "timestamp": "$time_iso8601", '
        # '"remote_addr": "$remote_addr", '
        #  '"body_bytes_sent": $body_bytes_sent, '
        #  '"request_time": $request_time, '
        #  '"response_status": $status, '
        #  '"request": "$request", '
        #  '"request_method": "$request_method", '
        #  '"host": "$host",'
        #  '"upstream_addr": "$upstream_addr",'
        #  '"http_x_forwarded_for": "$http_x_forwarded_for",'
        #  '"http_referrer": "$http_referer", '
        #  '"http_user_agent": "$http_user_agent", '
        #  '"http_version": "$server_protocol", '
        #  '"nginx_access": true }';
        # access_log /dev/stdout nginxlog_json;

    # See Move default writable paths to a dedicated directory (#119)
    # https://github.com/openresty/docker-openresty/issues/119
    client_body_temp_path /var/run/openresty/nginx-client-body;
    proxy_temp_path       /var/run/openresty/nginx-proxy;
    fastcgi_temp_path     /var/run/openresty/nginx-fastcgi;
    uwsgi_temp_path       /var/run/openresty/nginx-uwsgi;
    scgi_temp_path        /var/run/openresty/nginx-scgi;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    # 下面演示使用resty.limit.conn模块限制客户端tcp连接数
    # https://github.com/openresty/lua-resty-limit-traffic/tree/master/lib/resty/limit
    lua_shared_dict my_limit_conn_store 100m;
    access_by_lua_block {
   	-- well, we could put the require() and new() calls in our own Lua
        -- modules to save overhead. here we put them below just for
        -- convenience.

        local limit_conn = require "resty.limit.conn"

        -- limit the requests under 200 concurrent requests (normally just
	-- incoming connections unless protocols like SPDY is used) with
        -- a burst of 100 extra concurrent requests, that is, we delay
        -- requests under 300 concurrent connections and above 200
        -- connections, and reject any new requests exceeding 300
        -- connections.
        -- also, we assume a default request time of 0.5 sec, which can be
        -- dynamically adjusted by the leaving() call in log_by_lua below.
        -- 最大允许5+1个连接，允许1个突发连接，突发连接被延迟1秒
        local lim, err = limit_conn.new("my_limit_conn_store", 5, 1, 1)
        if not lim then
		ngx.log(ngx.ERR, "failed to instantiate a resty.limit.conn object: ", err)
		return ngx.exit(500)
        end

        -- the following call must be per-request.
        -- here we use the remote (IP) address as the limiting key
        local key = ngx.var.binary_remote_addr
        local delay, err = lim:incoming(key, true)
        if not delay then
        	if err == "rejected" then
                	return ngx.exit(503)
                end
                ngx.log(ngx.ERR, "failed to limit req: ", err)
                return ngx.exit(500)
        end

        if lim:is_committed() then
        	local ctx = ngx.ctx
                ctx.limit_conn = lim
                ctx.limit_conn_key = key
                ctx.limit_conn_delay = delay
        end

        -- the 2nd return value holds the current concurrency level
        -- for the specified key.
        local conn = err

        if delay >= 0.001 then
                -- the request exceeding the 200 connections ratio but below
                -- 300 connections, so
                -- we intentionally delay it here a bit to conform to the
                -- 200 connection limit.
                -- ngx.log(ngx.WARN, "delaying")
                ngx.sleep(delay)
        end
    }

    # content handler goes here. if it is content_by_lua, then you can
    # merge the Lua code above in access_by_lua into your
    # content_by_lua's Lua handler to save a little bit of CPU time.

    log_by_lua_block {
    	local ctx = ngx.ctx
        local lim = ctx.limit_conn
        if lim then
        	-- if you are using an upstream module in the content phase,
                -- then you probably want to use $upstream_response_time
    		-- instead of ($request_time - ctx.limit_conn_delay) below.
                local latency = tonumber(ngx.var.request_time) - ctx.limit_conn_delay
                local key = ctx.limit_conn_key
                assert(key)
                local conn, err = lim:leaving(key, latency)
                if not conn then
                	ngx.log(ngx.ERR,
                                "failed to record the connection leaving ",
                                "request: ", err)
                	return
                end
   	end
    }

    server {
    	listen       80;
    	server_name  localhost;
	
    	location / {
       		#root   /usr/local/openresty/nginx/html;
        	#index  index.html index.htm;
 		content_by_lua_block {
			ngx.sleep(0.5);
			ngx.header.content_type = "text/plain";
			ngx.say("Hello Dexterleslie.");
		}
    	}

    	error_page   500 502 503 504  /50x.html;
    	location = /50x.html {
        	root   /usr/local/openresty/nginx/html;
    	}
    }
}
