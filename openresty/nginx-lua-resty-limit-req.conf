# nginx.conf  --  docker-openresty
#
# This file is installed to:
#   `/usr/local/openresty/nginx/conf/nginx.conf`
# and is the file loaded by nginx at startup,
# unless the user specifies otherwise.
#
# It tracks the upstream OpenResty's `nginx.conf`, but removes the `server`
# section and adds this directive:
#     `include /etc/nginx/conf.d/*.conf;`
#
# The `docker-openresty` file `nginx.vh.default.conf` is copied to
# `/etc/nginx/conf.d/default.conf`.  It contains the `server section
# of the upstream `nginx.conf`.
#
# See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files
#

#user  nobody;
#worker_processes 1;

# Enables the use of JIT for regular expressions to speed-up their processing.
pcre_jit on;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

# 开启debug级别日志，否则ngx.log不能输出debug级别日志
# https://stackoverflow.com/questions/55975325/nothing-is-written-to-nginx-access-log-error-log-how-to-troubleshoot
error_log  logs/error.log  debug;

#pid        logs/nginx.pid;

events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    # Enables or disables the use of underscores in client request header fields.
    # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive.
    # underscores_in_headers off;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

        # Log in JSON Format
        # log_format nginxlog_json escape=json '{ "timestamp": "$time_iso8601", '
        # '"remote_addr": "$remote_addr", '
        #  '"body_bytes_sent": $body_bytes_sent, '
        #  '"request_time": $request_time, '
        #  '"response_status": $status, '
        #  '"request": "$request", '
        #  '"request_method": "$request_method", '
        #  '"host": "$host",'
        #  '"upstream_addr": "$upstream_addr",'
        #  '"http_x_forwarded_for": "$http_x_forwarded_for",'
        #  '"http_referrer": "$http_referer", '
        #  '"http_user_agent": "$http_user_agent", '
        #  '"http_version": "$server_protocol", '
        #  '"nginx_access": true }';
        # access_log /dev/stdout nginxlog_json;

    # See Move default writable paths to a dedicated directory (#119)
    # https://github.com/openresty/docker-openresty/issues/119
    client_body_temp_path /var/run/openresty/nginx-client-body;
    proxy_temp_path       /var/run/openresty/nginx-proxy;
    fastcgi_temp_path     /var/run/openresty/nginx-fastcgi;
    uwsgi_temp_path       /var/run/openresty/nginx-uwsgi;
    scgi_temp_path        /var/run/openresty/nginx-scgi;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    # 下面演示使用resty.limit.req模块限制客户端请求速率
    # https://github.com/openresty/lua-resty-limit-traffic/tree/master/lib/resty/limit
    lua_shared_dict my_limit_req_store 100m;
    access_by_lua_block {
    	-- well, we could put the require() and new() calls in our own Lua
        -- modules to save overhead. here we put them below just for
        -- convenience.

        local limit_req = require "resty.limit.req"

        -- limit the requests under 200 req/sec with a burst of 100 req/sec,
        -- that is, we delay requests under 300 req/sec and above 200
        -- req/sec, and reject any requests exceeding 300 req/sec.
	-- 1秒内最多只能5个请求，突发延迟队列为10，超出突发队列的请求被拒绝503
        local lim, err = limit_req.new("my_limit_req_store", 5, 10)
        if not lim then
        	ngx.log(ngx.ERR, "failed to instantiate a resty.limit.req object: ", err)
                return ngx.exit(500)
        end

        -- the following call must be per-request.
        -- here we use the remote (IP) address as the limiting key
        local key = ngx.var.binary_remote_addr
        local delay, err = lim:incoming(key, true)
        if not delay then
        	if err == "rejected" then
                	return ngx.exit(503)
                end
                ngx.log(ngx.ERR, "failed to limit req: ", err)
                return ngx.exit(500)
     	end

        if delay >= 0.001 then
            	-- the 2nd return value holds  the number of excess requests
                -- per second for the specified key. for example, number 31
                -- means the current request rate is at 231 req/sec for the
                -- specified key.
                local excess = err

                -- the request exceeding the 200 req/sec but below 300 req/sec,
                -- so we intentionally delay it here a bit to conform to the
                -- 200 req/sec rate.
		ngx.log(ngx.DEBUG, "+++++delay=" .. delay);
                ngx.sleep(delay)
   	end
    }

    server {
    	listen       80;
    	server_name  localhost;
	
    	location / {
       		#root   /usr/local/openresty/nginx/html;
        	#index  index.html index.htm;
 		content_by_lua_block {
			ngx.header.content_type = "text/plain";
			ngx.say("Hello Dexterleslie.");
		}
    	}

    	error_page   500 502 503 504  /50x.html;
    	location = /50x.html {
        	root   /usr/local/openresty/nginx/html;
    	}
    }
}
